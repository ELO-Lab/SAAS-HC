{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import optuna\n",
    "import subprocess\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choose_index():\n",
    "    global idx, df\n",
    "    return np.random.choice(idx, p=df.prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(command):\n",
    "    result = subprocess.run(command, capture_output=True)\n",
    "    assert (\n",
    "        result.returncode == 0\n",
    "    ), f\"\"\"\n",
    "command:\n",
    "{' '.join(command)}\n",
    "returncode: {result.returncode}\n",
    "stderr:\n",
    "{result.stderr.decode()}\n",
    "stdout:\n",
    "{result.stdout.decode()}\n",
    "\"\"\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_a_instance(mean_arr, std_arr, rho_arr, indv_ants_arr):\n",
    "    global debug_mode, debug_time, acopp_dir, df, sol_dir, postfix\n",
    "\n",
    "    df_idx = random_choose_index()\n",
    "    instance_name = df.loc[df_idx].instance\n",
    "    acopp_profit = df.loc[df_idx].acopp_profit\n",
    "\n",
    "    command = [\n",
    "        'python3',\n",
    "        f'{acopp_dir}/run.py',\n",
    "        '--acopp_dir',\n",
    "        str(acopp_dir),\n",
    "        '--instance_name',\n",
    "        instance_name,\n",
    "        '--run_only',\n",
    "        '--experiment',\n",
    "        # '--no_log',\n",
    "        '--sol_dir',\n",
    "        str(sol_dir),\n",
    "        '--silent',\n",
    "        '1',\n",
    "        \"--postfix\",\n",
    "        str(postfix),\n",
    "        \n",
    "        '--no_default',\n",
    "        \"--chain_flags\",\n",
    "        f\"--adapt_evap --cmaes --mean_ary {mean_arr} --std_ary {std_arr} --adpt_rho {rho_arr} --indv_ants {indv_ants_arr}\",\n",
    "    ]\n",
    "\n",
    "    if debug_mode:\n",
    "        command += [\"--time\", str(debug_time)]\n",
    "    \n",
    "    result = run_command(command)\n",
    "    stdout_log = result.stdout.decode()\n",
    "    profit = int(stdout_log)\n",
    "    \n",
    "    gain_percent = (profit - acopp_profit) / acopp_profit * 100\n",
    "    return gain_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_arr_flag(a_list):\n",
    "    arr_flag = map(str, a_list)\n",
    "    arr_flag = \":\".join(arr_flag)\n",
    "    return arr_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    global n_run_each_trail\n",
    "\n",
    "    indv_ants = trial.suggest_int(\"indv_ants\", 2, 50)\n",
    "    min_indv_ants = trial.suggest_int(\"min_indv_ants\", 2, indv_ants)\n",
    "    max_indv_ants = trial.suggest_int(\"max_indv_ants\", indv_ants, 50)\n",
    "\n",
    "    rho = trial.suggest_float(\"rho\", 0.01, 0.99)\n",
    "    min_rho = trial.suggest_float(\"min_rho\", 0.01, rho)\n",
    "    max_rho = trial.suggest_float(\"max_rho\", rho, 0.99)\n",
    "\n",
    "    alpha_mean = trial.suggest_float(\"alpha_mean\", 0.01, 10)\n",
    "    # mean + k*std <= upper_bound       <=> std <= (upper_bound - mean) / k\n",
    "    # mean - k*std >= lower_bound       <=> std <= (mean - lower_bound) / k\n",
    "    std_upper_bound = min((10 - alpha_mean), (alpha_mean - 0.01)) / 2\n",
    "    std_upper_bound = max(std_upper_bound, 0.01)\n",
    "    alpha_std = trial.suggest_float(\"alpha_std\", 0.01, std_upper_bound)\n",
    "\n",
    "    beta_mean = trial.suggest_float(\"beta_mean\", 0.01, 10)\n",
    "    std_upper_bound = min((10 - beta_mean), (beta_mean - 0.01)) / 2\n",
    "    std_upper_bound = max(std_upper_bound, 0.01)\n",
    "    beta_std = trial.suggest_float(\"beta_std\", 0.01, std_upper_bound)\n",
    "\n",
    "    par_a_mean = trial.suggest_float(\"par_a_mean\", 0.01, 1)\n",
    "    std_upper_bound = min((1 - par_a_mean), (par_a_mean - 0.01)) / 2\n",
    "    std_upper_bound = max(std_upper_bound, 0.01)\n",
    "    par_a_std = trial.suggest_float(\"par_a_std\", 0.01, std_upper_bound)\n",
    "\n",
    "    par_b_mean = trial.suggest_float(\"par_b_mean\", 0.01, 1)\n",
    "    std_upper_bound = min((1 - par_b_mean), (par_b_mean - 0.01)) / 2\n",
    "    std_upper_bound = max(std_upper_bound, 0.01)\n",
    "    par_b_std = trial.suggest_float(\"par_b_std\", 0.01, std_upper_bound)\n",
    "\n",
    "    par_c_mean = trial.suggest_float(\"par_c_mean\", 0.01, 1)\n",
    "    std_upper_bound = min((1 - par_c_mean), (par_c_mean - 0.01)) / 2\n",
    "    std_upper_bound = max(std_upper_bound, 0.01)\n",
    "    par_c_std = trial.suggest_float(\"par_c_std\", 0.01, std_upper_bound)\n",
    "\n",
    "    mean_arr = to_arr_flag([alpha_mean, beta_mean, par_a_mean, par_b_mean, par_c_mean])\n",
    "    std_arr = to_arr_flag([alpha_std, beta_std, par_a_std, par_b_std, par_c_std])\n",
    "    rho_arr = to_arr_flag([rho, min_rho, max_rho])\n",
    "    indv_ants_arr = to_arr_flag([indv_ants, min_indv_ants, max_indv_ants])\n",
    "\n",
    "    objective_value = 0\n",
    "    for i in range(n_run_each_trail):\n",
    "        objective_value += run_a_instance(mean_arr, std_arr, rho_arr, indv_ants_arr) / n_run_each_trail\n",
    "\n",
    "    return objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./es_ant_gain_percent.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(df.instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = np.random.choice(idx, p=df.prob)\n",
    "haha, df.loc[haha].instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acopp_dir = Path(\"../\")\n",
    "save_path = Path(\"./study.pkl\")\n",
    "sol_dir = Path(\"./solutions\")\n",
    "postfix = str(time.time())\n",
    "\n",
    "total_trial = 1000\n",
    "n_jobs = 3\n",
    "n_run_each_trail = 3\n",
    "save_each_n_trial = 1\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "idx = np.arange(len(df.instance))\n",
    "\n",
    "debug_mode = False\n",
    "# debug_mode = True\n",
    "debug_time = 10\n",
    "if debug_mode:\n",
    "    total_trial = 2\n",
    "    n_jobs = 2\n",
    "    save_each_n_trial = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = [\n",
    "    'python3',\n",
    "    f'{acopp_dir}/run.py',\n",
    "    '--acopp_dir',\n",
    "    str(acopp_dir),\n",
    "    '--build_only',\n",
    "    '--experiment'\n",
    "    ]\n",
    "result = run_command(command)\n",
    "print(result.stdout.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "# with open(save_path, \"wb\") as f:\n",
    "#     pickle.dump(study, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path, \"rb\") as f:\n",
    "    study = pickle.load(f)\n",
    "    \n",
    "while (len(study.trials) < total_trial):\n",
    "    study.optimize(objective, n_trials=save_each_n_trial, n_jobs=n_jobs)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(study, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
