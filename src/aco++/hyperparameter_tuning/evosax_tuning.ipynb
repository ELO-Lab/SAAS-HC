{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from evosax import BIPOP_CMA_ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choose_index(n):\n",
    "    global df_indexes, log_weight\n",
    "    return np.random.choice(df_indexes, n, p=log_weight, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(command):\n",
    "    result = subprocess.run(command, capture_output=True)\n",
    "    assert (\n",
    "        result.returncode == 0\n",
    "    ), f\"\"\"\n",
    "command:\n",
    "{' '.join(command)}\n",
    "returncode: {result.returncode}\n",
    "stderr:\n",
    "{result.stderr.decode()}\n",
    "stdout:\n",
    "{result.stdout.decode()}\n",
    "\"\"\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_a_instance(chain_flags, instance_name, acopp_profit, seed):\n",
    "    global debug_mode, debug_time, acopp_dir, sol_dir\n",
    "\n",
    "    command = [\n",
    "        'python3',\n",
    "        f'{acopp_dir}/run.py',\n",
    "        '--acopp_dir',\n",
    "        str(acopp_dir),\n",
    "        '--instance_name',\n",
    "        instance_name,\n",
    "        '--run_only',\n",
    "        '--experiment',\n",
    "        # '--no_log',\n",
    "        '--sol_dir',\n",
    "        str(sol_dir),\n",
    "        '--silent',\n",
    "        '1',\n",
    "        \"--postfix\",\n",
    "        str(time.time()),\n",
    "        \"--random_seed\",\n",
    "        str(seed),\n",
    "        \n",
    "        '--no_default',\n",
    "        \"--chain_flags\",\n",
    "        str(chain_flags),\n",
    "    ]\n",
    "\n",
    "    if debug_mode:\n",
    "        command += [\"--time\", str(debug_time)]\n",
    "    \n",
    "    result = run_command(command)\n",
    "    stdout_log = result.stdout.decode()\n",
    "    profit = int(stdout_log)\n",
    "    \n",
    "    gain_percent = (profit - acopp_profit) / acopp_profit * 100\n",
    "    return gain_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_arr_flag(a_list):\n",
    "    arr_flag = map(str, a_list)\n",
    "    arr_flag = \":\".join(arr_flag)\n",
    "    return arr_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chain_flags(params):\n",
    "    global index_dict, max_max_rho, min_min_rho, max_max_indv_ants, min_min_indv_ants\n",
    "    \n",
    "    pop_size = params[index_dict[\"pop_size\"]]\n",
    "\n",
    "    alpha_mean = params[index_dict[\"alpha_mean\"]]\n",
    "    beta_mean = params[index_dict[\"beta_mean\"]]\n",
    "    par_a_mean = params[index_dict[\"par_a_mean\"]]\n",
    "    par_b_mean = params[index_dict[\"par_b_mean\"]]\n",
    "    par_c_mean = params[index_dict[\"par_c_mean\"]]\n",
    "\n",
    "    alpha_std = params[index_dict[\"alpha_std\"]]\n",
    "    beta_std = params[index_dict[\"beta_std\"]]\n",
    "    par_a_std = params[index_dict[\"par_a_std\"]]\n",
    "    par_b_std = params[index_dict[\"par_b_std\"]]\n",
    "    par_c_std = params[index_dict[\"par_c_std\"]]\n",
    "\n",
    "    rho = params[index_dict[\"rho\"]]\n",
    "    indv_ants = params[index_dict[\"indv_ants\"]]\n",
    "\n",
    "    left_rho = params[index_dict[\"left_rho\"]]\n",
    "    _mid_rho = params[index_dict[\"_mid_rho\"]]\n",
    "    right_rho = params[index_dict[\"right_rho\"]]\n",
    "    sum_rho = left_rho + _mid_rho + right_rho\n",
    "    left_rho = left_rho / sum_rho * (max_max_rho - min_min_rho)\n",
    "    _mid_rho = _mid_rho / sum_rho * (max_max_rho - min_min_rho)\n",
    "    \n",
    "    min_rho = left_rho + min_min_rho\n",
    "    max_rho = min_rho + _mid_rho\n",
    "\n",
    "    left_indv_ants = params[index_dict[\"left_indv_ants\"]]\n",
    "    _mid_indv_ants = params[index_dict[\"_mid_indv_ants\"]]\n",
    "    right_indv_ants = params[index_dict[\"right_indv_ants\"]]\n",
    "    sum_indv_ants = left_indv_ants + _mid_indv_ants + right_indv_ants\n",
    "    left_indv_ants = left_indv_ants / sum_indv_ants * (max_max_indv_ants - min_min_indv_ants)\n",
    "    _mid_indv_ants = _mid_indv_ants / sum_indv_ants * (max_max_indv_ants - min_min_indv_ants)\n",
    "    \n",
    "    min_indv_ants = left_indv_ants + min_min_indv_ants\n",
    "    max_indv_ants = min_indv_ants + _mid_indv_ants\n",
    "\n",
    "    mean_arr = to_arr_flag([alpha_mean, beta_mean, par_a_mean, par_b_mean, par_c_mean])\n",
    "    std_arr = to_arr_flag([alpha_std, beta_std, par_a_std, par_b_std, par_c_std])\n",
    "    rho_arr = to_arr_flag([rho, min_rho, max_rho])\n",
    "    indv_ants_arr = to_arr_flag([indv_ants, min_indv_ants, max_indv_ants])\n",
    "\n",
    "    chain_flags = f\"--adapt_evap --cmaes --lambda {pop_size} --mean_ary {mean_arr} --std_ary {std_arr} --adpt_rho {rho_arr} --indv_ants {indv_ants_arr}\"\n",
    "    return chain_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_priority_order(row):\n",
    "    global min_gain\n",
    "    if row.gain_percent < 0:\n",
    "        return row.gain_percent - min_gain + 1\n",
    "    else:\n",
    "        return - row.gain_percent\n",
    "    \n",
    "\n",
    "def sort_by_priority(df):\n",
    "    global min_gain\n",
    "    min_gain = df.gain_percent.min()\n",
    "\n",
    "    df[\"priority_order\"] = df.apply(make_priority_order, axis=1)\n",
    "    df.sort_values(by=\"priority_order\", ascending=False, inplace=True)\n",
    "    df.drop(columns=[\"priority_order\"], inplace=True)\n",
    "\n",
    "\n",
    "def update_df(picked_idxes, gain_percents):\n",
    "    global df\n",
    "\n",
    "    gain_percents = gain_percents.T.mean(axis=1)\n",
    "    for i, df_idx in enumerate(picked_idxes):\n",
    "        df.loc[df_idx, \"gain_percent\"] = gain_percents[i]\n",
    "    sort_by_priority(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pop(pop_params):\n",
    "    global n_run_each_trail, executor, eval_call_count, df\n",
    "\n",
    "    tasks = []\n",
    "    chain_flagss = []\n",
    "    for params in pop_params:\n",
    "        chain_flagss.append(to_chain_flags(params))\n",
    "    picked_idxes = random_choose_index(n_run_each_trail)\n",
    "\n",
    "    for _chain_flags in chain_flagss:\n",
    "        for df_idx in picked_idxes:\n",
    "            tasks.append((\n",
    "                _chain_flags,\n",
    "                df.loc[df_idx].instance,\n",
    "                df.loc[df_idx].acopp_profit,\n",
    "                eval_call_count+1,\n",
    "                ))\n",
    "            eval_call_count += 1\n",
    "\n",
    "    gain_percents = executor.map(run_a_instance, *zip(*tasks))\n",
    "    gain_percents = np.array(list(gain_percents))\n",
    "    gain_percents = gain_percents.reshape((len(pop_params), n_run_each_trail))\n",
    "    \n",
    "    update_df(picked_idxes, gain_percents)\n",
    "    \n",
    "    objective_values = gain_percents\n",
    "    objective_values[objective_values >= 0] = 100\n",
    "    objective_values = objective_values.mean(axis=1)\n",
    "\n",
    "    fitness = jnp.array(- objective_values)\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_study():\n",
    "    global state, rng, strategy, es_params\n",
    "    global eval_call_count, index_dict\n",
    "    global save_path, backup_dir\n",
    "    global prev_best, prev_prev_best\n",
    "    global df, csv_path\n",
    "\n",
    "    study = {\n",
    "        \"strategy\": strategy,\n",
    "        \"es_params\": es_params,\n",
    "        \"state\": state,\n",
    "        \"rng\": rng,\n",
    "        \"index_dict\": index_dict,\n",
    "        \"prev_prev_best\": prev_prev_best,\n",
    "        \"prev_best\": prev_best,\n",
    "        \"eval_call_count\": eval_call_count,\n",
    "    }\n",
    "    if prev_best is not None:\n",
    "        study[\"best_chain_flags\"] = to_chain_flags(prev_best)\n",
    "    if prev_prev_best is not None:\n",
    "        study[\"second_best_chain_flags\"] = to_chain_flags(prev_prev_best)\n",
    "\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(study, f)\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Backup\n",
    "    _now = time.time()\n",
    "    df.to_csv(backup_dir / f\"{_now}.csv\", index=False)\n",
    "    with open(backup_dir / f\"{_now}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(study, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_study():\n",
    "    global state, rng, strategy, es_params\n",
    "    global eval_call_count, index_dict\n",
    "    global save_path\n",
    "    global prev_best, prev_prev_best\n",
    "    global df, csv_path\n",
    "\n",
    "    with open(save_path, \"rb\") as f:\n",
    "        study = pickle.load(f)\n",
    "    \n",
    "    eval_call_count = study[\"eval_call_count\"]\n",
    "    state = study[\"state\"]\n",
    "    rng = study[\"rng\"]\n",
    "    strategy = study[\"strategy\"]\n",
    "    prev_best = study[\"prev_best\"]\n",
    "    prev_prev_best = study[\"prev_prev_best\"]\n",
    "    index_dict = study[\"index_dict\"]\n",
    "    es_params = study[\"es_params\"]\n",
    "    df = pd.read_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_pop(pop_params):\n",
    "    global index_dict, eval_call_count, prev_best, prev_prev_best\n",
    "\n",
    "    pop_params = np.array(pop_params)\n",
    "    replace_idx = np.random.choice(np.arange(len(pop_params)), 2, replace=False)\n",
    "    if prev_best is not None:\n",
    "        pop_params[replace_idx[0]] = prev_best\n",
    "    if prev_prev_best is not None:\n",
    "        pop_params[replace_idx[1]] = prev_prev_best\n",
    "\n",
    "    pop_params[:, index_dict[\"indv_ants\"]] = np.round(pop_params[:, index_dict[\"indv_ants\"]])\n",
    "    pop_params[:, index_dict[\"pop_size\"]] = np.round(pop_params[:, index_dict[\"pop_size\"]])\n",
    "\n",
    "    return jnp.array(pop_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_percent():\n",
    "    global df\n",
    "    return (df.gain_percent >= 0).sum() / len(df.gain_percent) * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_mode = False\n",
    "# debug_mode = True\n",
    "debug_time = 9\n",
    "\n",
    "n_jobs = max(1, multiprocessing.cpu_count() // 2)\n",
    "acopp_dir = Path(\"../\")\n",
    "signal_path = Path(\"./signal.txt\")\n",
    "\n",
    "if not debug_mode:\n",
    "    n_run_each_trail = 10\n",
    "else:\n",
    "    n_run_each_trail = 2\n",
    "    optim_popsize = 4\n",
    "\n",
    "if not debug_mode:\n",
    "    experiment_name = \"evosax_tuning\"\n",
    "    experiment_dir = Path(\"/home/user2/experiments\") / experiment_name\n",
    "else:\n",
    "    experiment_name = \"temp_evosax_tuning\"\n",
    "    experiment_dir = Path(\"./\") / experiment_name\n",
    "\n",
    "csv_path = experiment_dir / \"gain_percent.csv\"\n",
    "save_path = experiment_dir / \"study.pkl\"\n",
    "backup_dir = experiment_dir / \"backup\"\n",
    "sol_dir = experiment_dir / \"solutions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_min_indv_ants = 2\n",
    "max_max_indv_ants = 105\n",
    "min_min_rho = 0.01\n",
    "max_max_rho = 0.99"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "os.makedirs(sol_dir, exist_ok=True)\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "os.makedirs(save_path.parent, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build\n",
    "assert os.path.isdir(acopp_dir)\n",
    "command = [\n",
    "    'python3',\n",
    "    f'{acopp_dir}/run.py',\n",
    "    '--acopp_dir',\n",
    "    str(acopp_dir),\n",
    "    '--build_only',\n",
    "    '--experiment'\n",
    "    ]\n",
    "result = run_command(command)\n",
    "print(result.stdout.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_instance = 432\n",
    "\n",
    "df_indexes = np.arange(n_instance)\n",
    "\n",
    "log_weight = np.log(n_instance + 1) - np.log(df_indexes + 1)\n",
    "log_weight /= log_weight.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANCE: One time preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(csv_path)\n",
    "\n",
    "# variable_list = (\n",
    "#     \"pop_size\",\n",
    "\n",
    "#     \"alpha_mean\",\n",
    "#     \"beta_mean\",\n",
    "#     \"par_a_mean\",\n",
    "#     \"par_b_mean\",\n",
    "#     \"par_c_mean\",\n",
    "\n",
    "#     \"alpha_std\",\n",
    "#     \"beta_std\",\n",
    "#     \"par_a_std\",\n",
    "#     \"par_b_std\",\n",
    "#     \"par_c_std\",\n",
    "\n",
    "#     \"rho\",\n",
    "#     \"left_rho\",\n",
    "#     \"_mid_rho\",\n",
    "#     \"right_rho\",\n",
    "\n",
    "#     \"indv_ants\",\n",
    "#     \"left_indv_ants\",\n",
    "#     \"_mid_indv_ants\",\n",
    "#     \"right_indv_ants\",\n",
    "# )\n",
    "\n",
    "# index_dict = dict()\n",
    "# for idx, key in enumerate(variable_list):\n",
    "#     index_dict[key] = idx\n",
    "\n",
    "# dim = len(index_dict)\n",
    "# if not debug_mode:\n",
    "#     optim_popsize = int(np.floor(4 + 3 * np.log(dim)))\n",
    "# rng = jax.random.PRNGKey(int(time.time()))\n",
    "# strategy = BIPOP_CMA_ES(popsize=optim_popsize, num_dims=dim)\n",
    "# es_params = strategy.default_params\n",
    "# eval_call_count = 0\n",
    "# clip_max= np.zeros((dim,))\n",
    "# clip_min= np.zeros((dim,))\n",
    "# init_min= np.zeros((dim,))\n",
    "# init_max= np.zeros((dim,))\n",
    "# sigma_init= np.zeros((dim,))\n",
    "# prev_best = None\n",
    "# prev_prev_best = None\n",
    "\n",
    "# idx = index_dict[\"pop_size\"]\n",
    "# clip_min[idx] = 8\n",
    "# clip_max[idx] = 25\n",
    "# init_min[idx] = init_max[idx] = 20\n",
    "# sigma_init[idx] = (clip_max[idx] - clip_min[idx]) / 5\n",
    "\n",
    "# idx = index_dict[\"indv_ants\"]\n",
    "# clip_min[idx] = 2\n",
    "# clip_max[idx] = 15\n",
    "# init_min[idx] = init_max[idx] = 2\n",
    "# sigma_init[idx] = (clip_max[idx] - clip_min[idx]) / 5\n",
    "\n",
    "# left_idx = index_dict[\"left_indv_ants\"]\n",
    "# _mid_idx = index_dict[\"_mid_indv_ants\"]\n",
    "# right_idx = index_dict[\"right_indv_ants\"]\n",
    "# clip_min[left_idx] = clip_min[_mid_idx] = clip_min[right_idx] = 0\n",
    "# clip_max[left_idx] = clip_max[_mid_idx] = clip_max[right_idx] = 1\n",
    "# sigma_init[left_idx] = sigma_init[_mid_idx] = sigma_init[right_idx] = (1 - 0) / 5\n",
    "# min_indv_ants = 10\n",
    "# max_indv_ants = 100\n",
    "# min_indv_ants = (min_indv_ants - min_min_indv_ants) / (max_max_indv_ants - min_min_indv_ants)\n",
    "# max_indv_ants = (max_indv_ants - min_min_indv_ants) / (max_max_indv_ants - min_min_indv_ants)\n",
    "# init_min[left_idx] = init_max[left_idx] = min_indv_ants - 0\n",
    "# init_min[_mid_idx] = init_max[_mid_idx] = max_indv_ants - min_indv_ants\n",
    "# init_min[right_idx] = init_max[right_idx] = 1 - max_indv_ants\n",
    "\n",
    "# idx = index_dict[\"rho\"]\n",
    "# clip_min[idx] = 0.01\n",
    "# clip_max[idx] = 0.99\n",
    "# init_min[idx] = init_max[idx] = 0.5\n",
    "# sigma_init[idx] = 0.253226\n",
    "\n",
    "# left_idx = index_dict[\"left_rho\"]\n",
    "# _mid_idx = index_dict[\"_mid_rho\"]\n",
    "# right_idx = index_dict[\"right_rho\"]\n",
    "# clip_min[left_idx] = clip_min[_mid_idx] = clip_min[right_idx] = 0\n",
    "# clip_max[left_idx] = clip_max[_mid_idx] = clip_max[right_idx] = 1\n",
    "# sigma_init[left_idx] = sigma_init[_mid_idx] = sigma_init[right_idx] = (1 - 0) / 5\n",
    "# min_rho = 0.1\n",
    "# max_rho = 0.99\n",
    "# min_rho = (min_rho - min_min_rho) / (max_max_rho - min_min_rho)\n",
    "# max_rho = (max_rho - min_min_rho) / (max_max_rho - min_min_rho)\n",
    "# init_min[left_idx] = init_max[left_idx] = min_rho - 0\n",
    "# init_min[_mid_idx] = init_max[_mid_idx] = max_rho - min_rho\n",
    "# init_min[right_idx] = init_max[right_idx] = 1 - max_rho\n",
    "\n",
    "# idx = index_dict[\"alpha_mean\"]\n",
    "# std_idx = index_dict[\"alpha_std\"]\n",
    "# clip_min[idx] = 0.01\n",
    "# clip_max[idx] = 10\n",
    "# init_min[idx] = init_max[idx] = 1.55\n",
    "# sigma_init[idx] = 1.507\n",
    "# clip_min[std_idx] = 0.01\n",
    "# clip_max[std_idx] = (clip_max[idx] - clip_min[idx]) / 2\n",
    "# init_min[std_idx] = init_max[std_idx] = sigma_init[idx]\n",
    "# sigma_init[std_idx] = (clip_max[std_idx] - clip_min[std_idx]) / 5\n",
    "\n",
    "# idx = index_dict[\"beta_mean\"]\n",
    "# std_idx = index_dict[\"beta_std\"]\n",
    "# clip_min[idx] = 0.01\n",
    "# clip_max[idx] = 10\n",
    "# init_min[idx] = init_max[idx] = 4.89\n",
    "# sigma_init[idx] = 2.046\n",
    "# clip_min[std_idx] = 0.01\n",
    "# clip_max[std_idx] = (clip_max[idx] - clip_min[idx]) / 2\n",
    "# init_min[std_idx] = init_max[std_idx] = sigma_init[idx]\n",
    "# sigma_init[std_idx] = (clip_max[std_idx] - clip_min[std_idx]) / 5\n",
    "\n",
    "# idx = index_dict[\"par_a_mean\"]\n",
    "# std_idx = index_dict[\"par_a_std\"]\n",
    "# clip_min[idx] = 0.01\n",
    "# clip_max[idx] = 1\n",
    "# init_min[idx] = init_max[idx] = 0.3\n",
    "# sigma_init[idx] = 0.2\n",
    "# clip_min[std_idx] = 0.01\n",
    "# clip_max[std_idx] = (clip_max[idx] - clip_min[idx]) / 2\n",
    "# init_min[std_idx] = init_max[std_idx] = sigma_init[idx]\n",
    "# sigma_init[std_idx] = (clip_max[std_idx] - clip_min[std_idx]) / 5\n",
    "\n",
    "# idx = index_dict[\"par_b_mean\"]\n",
    "# std_idx = index_dict[\"par_b_std\"]\n",
    "# clip_min[idx] = 0.01\n",
    "# clip_max[idx] = 1\n",
    "# init_min[idx] = init_max[idx] = 0.7\n",
    "# sigma_init[idx] = 0.2\n",
    "# clip_min[std_idx] = 0.01\n",
    "# clip_max[std_idx] = (clip_max[idx] - clip_min[idx]) / 2\n",
    "# init_min[std_idx] = init_max[std_idx] = sigma_init[idx]\n",
    "# sigma_init[std_idx] = (clip_max[std_idx] - clip_min[std_idx]) / 5\n",
    "\n",
    "# idx = index_dict[\"par_c_mean\"]\n",
    "# std_idx = index_dict[\"par_c_std\"]\n",
    "# clip_min[idx] = 0.01\n",
    "# clip_max[idx] = 1\n",
    "# init_min[idx] = init_max[idx] = 0.9\n",
    "# sigma_init[idx] = 0.2\n",
    "# clip_min[std_idx] = 0.01\n",
    "# clip_max[std_idx] = (clip_max[idx] - clip_min[idx]) / 2\n",
    "# init_min[std_idx] = init_max[std_idx] = sigma_init[idx]\n",
    "# sigma_init[std_idx] = (clip_max[std_idx] - clip_min[std_idx]) / 5\n",
    "\n",
    "# es_params = es_params.replace(\n",
    "#         strategy_params=es_params.strategy_params.replace(\n",
    "#             clip_min=jnp.array(clip_min),\n",
    "#             clip_max=jnp.array(clip_max),\n",
    "#             init_min=jnp.array(init_min),\n",
    "#             init_max=jnp.array(init_max),\n",
    "#             sigma_init=jnp.array(sigma_init),\n",
    "#             )\n",
    "#         )\n",
    "# state = strategy.initialize(rng, es_params)\n",
    "\n",
    "# assert not os.path.exists(save_path)\n",
    "# assert not os.path.exists(save_path)\n",
    "# assert not os.path.exists(save_path)\n",
    "# save_study()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_study()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "    # minimize\n",
    "    while True:\n",
    "        rng, rng_ask = jax.random.split(rng, 2)\n",
    "\n",
    "        if state.restart_state.restart_next:\n",
    "            print(f\"--> Restarted Strategy: {eval_call_count} eval calls\")\n",
    "            print_update = True\n",
    "        else:\n",
    "            print_update = False\n",
    "\n",
    "        x, state = strategy.ask(rng_ask, state, es_params)\n",
    "\n",
    "        if print_update:\n",
    "            print(f\"--> New Popsize: {state.restart_state.active_popsize}\")\n",
    "\n",
    "        x = modify_pop(x)\n",
    "        fitness = evaluate_pop(x)\n",
    "\n",
    "        prev_prev_best = prev_best\n",
    "        prev_best = x[fitness.argmin()] # minimize\n",
    "\n",
    "        state = strategy.tell(x, fitness, state, es_params)\n",
    "        state = state.replace(\n",
    "            restart_state = state.restart_state.replace(\n",
    "                restart_next = state.restart_state.restart_next.any()\n",
    "            )\n",
    "        )\n",
    "        save_study()\n",
    "\n",
    "        print(f\"eval_call_count: {eval_call_count} | gen_mean_fitness: {fitness.mean():.4f} | win_percent: {win_percent()} | best_chain_flags: {to_chain_flags(prev_best)}\")\n",
    "\n",
    "        with open(signal_path, \"rt\") as f:\n",
    "            if f.read() == \"BREAK\":\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
